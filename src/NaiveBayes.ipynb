{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import math\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load csv into dense matrix, then converts it to sparse matrix\n",
    "If \"res/sparse_training.data\" exists, **DO NOT** run cell as it will take awhile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dense_matrix = np.zeros(shape=(21, 61188), dtype=np.int16)\n",
    "with open('../res/training.csv', 'r') as train_stream:\n",
    "    for i, line in enumerate(train_stream):\n",
    "        line_int = np.array(list(map(int, line.split(','))), dtype=np.int16)\n",
    "        doc_label = line_int[-1]\n",
    "        dense_matrix[doc_label] += line_int[1:-1]\n",
    "        print(i)\n",
    "    sparse_training = sparse.csr_matrix(dense_matrix)\n",
    "    sparse.save_npz('../res/sparse_training.data',sparse_training)\n",
    "    print(sparse_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "  (1, 0)\t9\n",
      "  (1, 1)\t53\n",
      "  (1, 2)\t237\n",
      "  (1, 3)\t11\n",
      "  (1, 4)\t48\n",
      "  (1, 5)\t36\n",
      "  (1, 6)\t7\n",
      "  (1, 7)\t1\n",
      "  (1, 8)\t31\n",
      "  (1, 9)\t127\n",
      "  (1, 10)\t5\n",
      "  (1, 11)\t4336\n",
      "  (1, 12)\t19\n",
      "  (1, 13)\t24\n",
      "  (1, 14)\t46\n",
      "  (1, 15)\t597\n",
      "  (1, 16)\t267\n",
      "  (1, 17)\t12\n",
      "  (1, 18)\t9\n",
      "  (1, 19)\t15\n",
      "  (1, 20)\t2\n",
      "  (1, 21)\t3\n",
      "  (1, 22)\t2985\n",
      "  (1, 23)\t4\n",
      "  (1, 24)\t325\n",
      "  :\t:\n",
      "  (20, 61146)\t1\n",
      "  (20, 61147)\t1\n",
      "  (20, 61148)\t1\n",
      "  (20, 61149)\t2\n",
      "  (20, 61150)\t1\n",
      "  (20, 61151)\t1\n",
      "  (20, 61152)\t1\n",
      "  (20, 61153)\t1\n",
      "  (20, 61154)\t1\n",
      "  (20, 61169)\t2\n",
      "  (20, 61170)\t2\n",
      "  (20, 61171)\t2\n",
      "  (20, 61172)\t3\n",
      "  (20, 61173)\t4\n",
      "  (20, 61174)\t2\n",
      "  (20, 61175)\t3\n",
      "  (20, 61176)\t6\n",
      "  (20, 61177)\t1\n",
      "  (20, 61178)\t2\n",
      "  (20, 61179)\t2\n",
      "  (20, 61183)\t2\n",
      "  (20, 61184)\t2\n",
      "  (20, 61185)\t2\n",
      "  (20, 61186)\t2\n",
      "  (20, 61187)\t2\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "sparse_training_data = sparse.load_npz('../res/sparse_training.data.npz')\n",
    "# print(sparse_training_data[21, 3])  \n",
    "print(sparse_training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating global vars and consts"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "UNIQUE_VOCAB = 61188\n",
    "TOTAL_VOCAB = sparse_training_data.sum()\n",
    "BETA = 1/TOTAL_VOCAB\n",
    "ALPHA = 1 + BETA\n",
    "\n",
    "set_list = [set() for x in range(0, 20)]\n",
    "class_row_dict = dict(zip(list(range(1, 21)), set_list))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Counting Priors and words"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[0.         0.04025    0.052      0.05183333 0.05358333 0.05016667\n",
      " 0.0525     0.0515     0.05116667 0.05408333 0.05233333 0.05383333\n",
      " 0.05325    0.05216667 0.05175    0.05308333 0.05425    0.04833333\n",
      " 0.04941667 0.03891667 0.03558333]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "word_id_ranges = list(range(1, 61189))\n",
    "column_names =  ['doc_id'] + word_id_ranges + ['label']\n",
    "prior_counts = np.zeros(21, dtype=np.int16)\n",
    "i = 0\n",
    "for data_chunk in pd.read_csv('../res/training.csv', header=None, chunksize=200, names=column_names, usecols=['label']): \n",
    "    for _, row in data_chunk.iterrows():\n",
    "        current_label = row['label']\n",
    "        class_row_dict[current_label].add(i)\n",
    "        i += 1\n",
    "\n",
    "for j in range(1, 21):\n",
    "    prior_counts[j] = len(class_row_dict[j])\n",
    "\n",
    "prior_counts = prior_counts / prior_counts.sum()\n",
    "print(prior_counts) "
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Naive Bayes\n",
    "formula from the proj2 PDF"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def multinomial_naive_bayes(row, row_total_words, debug_prints = False)->int:\n",
    "    if debug_prints: print(row_total_words, row)\n",
    "        \n",
    "    map_denom = np.zeros(21, dtype = np.float64)\n",
    "    for i in range(1, 21):\n",
    "        map_denom[i] = sparse_training_data[i].sum() + ((ALPHA - 1) * TOTAL_VOCAB)\n",
    "        \n",
    "    k = ALPHA - 1\n",
    "    max_prob_class = [-math.inf, -1]\n",
    "    for doc_label in range(1, 21):\n",
    "        running_sum = 0\n",
    "        for word_i, num_words_at_i in row:\n",
    "            running_sum += math.log2((sparse_training_data[doc_label, word_i] + k)/map_denom[doc_label])\n",
    "        posterior = running_sum + math.log2(prior_counts[doc_label])\n",
    "        if posterior > max_prob_class[0]:\n",
    "            max_prob_class[0] = posterior\n",
    "            max_prob_class[1] = doc_label\n",
    "\n",
    "    if debug_prints: print(max_prob_class)\n",
    "    return max_prob_class[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "def bernoulli_naive_bayes(row, row_total_words, debug_prints = False)->int:\n",
    "    if debug_prints: print(row_total_words, row)\n",
    "\n",
    "    num_zeros = UNIQUE_VOCAB - len(row)\n",
    "    max_prob_class = [-math.inf, -1]\n",
    "    k = ALPHA - 1\n",
    "\n",
    "    # prob_not_appearing = (0+k) / denom\n",
    "    # # prob_of_doc = 1/20  # Not needed because all will be multiplied by it\n",
    "    # unique_words  = 0\n",
    "    for doc_label in range(1, 21):\n",
    "       \n",
    "        posterior = 0\n",
    "        if posterior > max_prob_class[0]:\n",
    "            max_prob_class[0] = posterior\n",
    "            max_prob_class[1] = doc_label\n",
    "\n",
    "    if debug_prints: print(max_prob_class)\n",
    "    return max_prob_class[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training Test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "def test_training(bayes_function):\n",
    "    sparse_matrix = sparse.load_npz('../res/nb_training_data.npz')\n",
    "    training_data_coo = sparse_matrix.tocoo()\n",
    "    \n",
    "    row_total_words = training_data_coo.A.sum(axis=1)\n",
    "    correct = 0\n",
    "    row = []\n",
    "    for row_i, word_i, val in zip(training_data_coo.row, training_data_coo.col, training_data_coo.data):\n",
    "        if word_i != 61188:\n",
    "            row.append((word_i, val))\n",
    "        else:\n",
    "            classification = bayes_function(row, row_total_words[row_i] - val)\n",
    "            correct += 1 if classification == val else 0\n",
    "            row.clear()\n",
    "            if not row_i % 200:\n",
    "                print('At row:', row_i)\n",
    "    print(\"Finished\")\n",
    "    print(f\"accuracy: {(correct / row_i) * 100}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classification and Writing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "def test_and_write(bayes_function, write_path):\n",
    "    sparse_matrix = sparse.load_npz('../res/nb_testing_data.npz')\n",
    "    testing_data_coo = sparse_matrix.tocoo()\n",
    "    with open(write_path, 'w') as out_stream:\n",
    "        out_stream.write(\"id,class\\n\")\n",
    "    \n",
    "        row_total_words = testing_data_coo.A.sum(axis=1)\n",
    "        row_offset = 12000\n",
    "        current_row = 12000\n",
    "        row = []\n",
    "        for row_i, word_i, num_words_at_i in zip(testing_data_coo.row + row_offset, testing_data_coo.col, testing_data_coo.data):\n",
    "            if row_i == current_row:\n",
    "                row.append((word_i, num_words_at_i))\n",
    "            else:\n",
    "                predicted_label = bayes_function(row, row_total_words[row_i - row_offset])\n",
    "                out_stream.write(f'{row_i},{predicted_label}\\n')\n",
    "                row.clear()\n",
    "                current_row = row_i\n",
    "                if not current_row % 200:\n",
    "                    print('At row:', current_row)\n",
    "    print(\"File written\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing\n",
    "- multinomial"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Finished\n",
      "accuracy: 99.02491874322861%\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "test_training(multinomial_naive_bayes)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', (stop - start) / 60, 'minutes.') "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "At row: 12200\n",
      "At row: 12400\n",
      "At row: 12600\n",
      "At row: 12800\n",
      "At row: 13000\n",
      "At row: 13200\n",
      "At row: 13400\n",
      "At row: 13600\n",
      "At row: 13800\n",
      "At row: 14000\n",
      "At row: 14200\n",
      "At row: 14400\n",
      "At row: 14600\n",
      "At row: 14800\n",
      "At row: 15000\n",
      "At row: 15200\n",
      "At row: 15400\n",
      "At row: 15600\n",
      "At row: 15800\n",
      "At row: 16000\n",
      "At row: 16200\n",
      "At row: 16400\n",
      "At row: 16600\n",
      "At row: 16800\n",
      "At row: 17000\n",
      "At row: 17200\n",
      "At row: 17400\n",
      "At row: 17600\n",
      "At row: 17800\n",
      "At row: 18000\n",
      "At row: 18200\n",
      "At row: 18400\n",
      "At row: 18600\n",
      "File written\n",
      "Time:  966.1413919999977\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "test_and_write(multinomial_naive_bayes, '../results/multinomial_NB_results.csv')\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', (stop - start) / 60, 'minutes.') "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Bernoulli"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "test_training(bernoulli_naive_bayes)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', (stop - start) / 60, 'minutes.') "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "test_and_write(bernoulli_naive_bayes, '../results/bernoulli_NB_results.csv')\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', (stop - start) / 60, 'minutes.') "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "61189\n",
      "61189\n",
      "61189\n",
      "2\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# with open('../res/testing.csv', 'r') as train_stream:\n",
    "#     count = 0\n",
    "#     for i, line in enumerate(train_stream):\n",
    "#         current_line = np.array(list(map(int, line.split(','))), dtype=np.int16)\n",
    "#         print(len(current_line))\n",
    "#         if i == 2:\n",
    "#             break\n",
    "#     print(i)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}