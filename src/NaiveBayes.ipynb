{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load csv into dense matrix, then converts it to sparse matrix\n",
    "If \"res/sparse_training.data\" exists, **DO NOT** run cell as it will take awhile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def load_matrix():\n",
    "    dense_matrix = np.zeros(shape=(21, 61188), dtype=np.int16)\n",
    "    with open('../res/training.csv', 'r') as train_stream:\n",
    "        for i, line in enumerate(train_stream):\n",
    "            line_int = np.array(list(map(int, line.split(','))), dtype=np.int16)\n",
    "            doc_label = line_int[-1]\n",
    "            dense_matrix[doc_label] += line_int[1:-1]\n",
    "            print(i)\n",
    "        sparse_training = sparse.csr_matrix(dense_matrix)\n",
    "        sparse.save_npz('../res/sparse_training.data',sparse_training)\n",
    "        \n",
    "# load_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "  (1, 0)\t9\n",
      "  (1, 1)\t53\n",
      "  (1, 2)\t237\n",
      "  (1, 3)\t11\n",
      "  (1, 4)\t48\n",
      "  (1, 5)\t36\n",
      "  (1, 6)\t7\n",
      "  (1, 7)\t1\n",
      "  (1, 8)\t31\n",
      "  (1, 9)\t127\n",
      "  (1, 10)\t5\n",
      "  (1, 11)\t4336\n",
      "  (1, 12)\t19\n",
      "  (1, 13)\t24\n",
      "  (1, 14)\t46\n",
      "  (1, 15)\t597\n",
      "  (1, 16)\t267\n",
      "  (1, 17)\t12\n",
      "  (1, 18)\t9\n",
      "  (1, 19)\t15\n",
      "  (1, 20)\t2\n",
      "  (1, 21)\t3\n",
      "  (1, 22)\t2985\n",
      "  (1, 23)\t4\n",
      "  (1, 24)\t325\n",
      "  :\t:\n",
      "  (20, 61146)\t1\n",
      "  (20, 61147)\t1\n",
      "  (20, 61148)\t1\n",
      "  (20, 61149)\t2\n",
      "  (20, 61150)\t1\n",
      "  (20, 61151)\t1\n",
      "  (20, 61152)\t1\n",
      "  (20, 61153)\t1\n",
      "  (20, 61154)\t1\n",
      "  (20, 61169)\t2\n",
      "  (20, 61170)\t2\n",
      "  (20, 61171)\t2\n",
      "  (20, 61172)\t3\n",
      "  (20, 61173)\t4\n",
      "  (20, 61174)\t2\n",
      "  (20, 61175)\t3\n",
      "  (20, 61176)\t6\n",
      "  (20, 61177)\t1\n",
      "  (20, 61178)\t2\n",
      "  (20, 61179)\t2\n",
      "  (20, 61183)\t2\n",
      "  (20, 61184)\t2\n",
      "  (20, 61185)\t2\n",
      "  (20, 61186)\t2\n",
      "  (20, 61187)\t2\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "sparse_training_data = sparse.load_npz('../res/sparse_training.data.npz')\n",
    "# print(sparse_training_data[21, 3])  \n",
    "print(sparse_training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating global vars and consts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "UNIQUE_VOCAB = 61188\n",
    "TOTAL_VOCAB = sparse_training_data.sum()\n",
    "\n",
    "# the pxs used for mutual information\n",
    "pxs = np.zeros(61188, dtype=np.float)\n",
    "pxs_initialized=False\n",
    "\n",
    "set_list = [set() for x in range(0, 20)]\n",
    "class_row_dict = dict(zip(list(range(1, 21)), set_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting Priors and words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[0.         0.04844692 0.05053315 0.05006954 0.05146036 0.04798331\n",
      " 0.05146036 0.05215577 0.05238758 0.05076495 0.04983774 0.05146036\n",
      " 0.04983774 0.04937413 0.05006954 0.05053315 0.05099675 0.05006954\n",
      " 0.05146036 0.04612888 0.04496987]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "def count_priors():\n",
    "    word_id_ranges = list(range(1, 61189))\n",
    "    column_names =  ['doc_id'] + word_id_ranges + ['label']\n",
    "    p_counts = np.zeros(21, dtype=np.int16)\n",
    "    for i, data_chunk in enumerate(pd.read_csv('../res/training.csv', header=None, chunksize=200, names=column_names, usecols=['label'])): \n",
    "        for _, row in data_chunk.iterrows():\n",
    "            current_label = row['label']\n",
    "            class_row_dict[current_label].add(i)\n",
    "            i += 1\n",
    "    \n",
    "    for j in range(1, 21):\n",
    "        p_counts[j] = len(class_row_dict[j])\n",
    "    \n",
    "    return p_counts / p_counts.sum()\n",
    "\n",
    "prior_counts = count_priors()\n",
    "print(prior_counts) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Px|Y used for both Question 6 and also Fast NB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Pxgy\n",
    "MUTUAL_BETA= 0.004\n",
    "pxgy = np.array(sparse_training_data.todense(), dtype=np.float)\n",
    "total_words = {}\n",
    "for i in range(1, 21):\n",
    "    total_words[i] = pxgy[i].sum()\n",
    "    pxgy[i]  = (pxgy[i] + MUTUAL_BETA) / (total_words[i] + (MUTUAL_BETA * TOTAL_VOCAB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutual Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Useful and lease useful words in the whole document. Using entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most usefull words!\n",
      "doves\n",
      "uxarch\n",
      "amphiboly\n",
      "unipress\n",
      "equivocation\n",
      "vaxstation\n",
      "stellix\n",
      "joanne\n",
      "newbauer\n",
      "lewart\n",
      "allbery\n",
      "wjh\n",
      "xgoodies\n",
      "pierces\n",
      "muscularly\n",
      "totty\n",
      "listname\n",
      "xew\n",
      "slit\n",
      "libwxm\n",
      "antiquitam\n",
      "crumenam\n",
      "univision\n",
      "adnt\n",
      "ncsuvm\n",
      "chirurgie\n",
      "boutilie\n",
      "xware\n",
      "netoprwa\n",
      "kck\n",
      "poop\n",
      "emits\n",
      "doleh\n",
      "conor\n",
      "giza\n",
      "shite\n",
      "sinkhole\n",
      "reification\n",
      "nuucp\n",
      "usrx\n",
      "baruch\n",
      "quinton\n",
      "favourating\n",
      "ehm\n",
      "moondog\n",
      "fileselector\n",
      "ryner\n",
      "tamm\n",
      "wergo\n",
      "foolishly\n",
      "xpic\n",
      "serverses\n",
      "navigations\n",
      "hangspace\n",
      "convenients\n",
      "respectedly\n",
      "divaev\n",
      "rusian\n",
      "fsck\n",
      "ifconfig\n",
      "mxterm\n",
      "ziemans\n",
      "woodlice\n",
      "moonsoft\n",
      "chiquita\n",
      "scherf\n",
      "multilist\n",
      "stna\n",
      "causa\n",
      "dgac\n",
      "michanek\n",
      "searle\n",
      "bouron\n",
      "connolly\n",
      "xcrichtext\n",
      "equivalently\n",
      "thyme\n",
      "ignorantium\n",
      "xmt\n",
      "dovetail\n",
      "ceilidh\n",
      "arguer\n",
      "multidrop\n",
      "smebsb\n",
      "wccreate\n",
      "wcchildren\n",
      "nssl\n",
      "unpacking\n",
      "conformant\n",
      "hotbed\n",
      "cwm\n",
      "pswm\n",
      "jbis\n",
      "carlotto\n",
      "championed\n",
      "hoagland\n",
      "facelike\n",
      "kerwin\n",
      "prather\n",
      "tycchow\n",
      "\n",
      "----------------------------------\n",
      "useless words:\n",
      "\n",
      "the\n",
      "to\n",
      "of\n",
      "and\n",
      "in\n",
      "is\n",
      "that\n",
      "it\n",
      "for\n",
      "you\n",
      "on\n",
      "this\n",
      "have\n",
      "be\n",
      "with\n",
      "not\n",
      "are\n",
      "or\n",
      "as\n",
      "if\n",
      "but\n",
      "edu\n",
      "they\n",
      "was\n",
      "can\n",
      "from\n",
      "at\n",
      "my\n",
      "by\n",
      "an\n",
      "there\n",
      "what\n",
      "all\n",
      "will\n",
      "would\n",
      "one\n",
      "do\n",
      "writes\n",
      "about\n",
      "com\n",
      "he\n",
      "so\n",
      "we\n",
      "has\n",
      "your\n",
      "no\n",
      "any\n",
      "me\n",
      "article\n",
      "some\n",
      "out\n",
      "like\n",
      "which\n",
      "don\n",
      "just\n",
      "who\n",
      "more\n",
      "up\n",
      "when\n",
      "get\n",
      "know\n",
      "only\n",
      "other\n",
      "their\n",
      "how\n",
      "people\n",
      "them\n",
      "were\n",
      "than\n",
      "had\n",
      "also\n",
      "think\n",
      "been\n",
      "use\n",
      "his\n",
      "does\n",
      "time\n",
      "then\n",
      "new\n",
      "good\n",
      "am\n",
      "these\n",
      "could\n",
      "should\n",
      "well\n",
      "may\n",
      "very\n",
      "now\n",
      "because\n",
      "even\n",
      "into\n",
      "apr\n",
      "much\n",
      "ve\n",
      "see\n",
      "system\n",
      "two\n",
      "way\n",
      "first\n",
      "make\n"
     ]
    }
   ],
   "source": [
    "xjointy = pxgy.copy()\n",
    "enthropy = np.zeros(61188)\n",
    "for i in range(1, 21):\n",
    "    xjointy[i] *= prior_counts[i]\n",
    "for i in range(61188):\n",
    "    marginal_val = xjointy[:,i].sum()\n",
    "    enthropy[i] =  marginal_val * np.log2(marginal_val)\n",
    "sorted_indices = enthropy.argsort()\n",
    "vocab_df = pd.read_csv('../res/vocabulary.txt', sep='\\n', header=None, names=[\"word\"])\n",
    "print(\"Most usefull words!\")\n",
    "for x in sorted_indices[-100:][::-1]:\n",
    "    print(vocab_df.iloc[x]['word'])\n",
    "    \n",
    "print(\"\\n----------------------------------\")\n",
    "print(\"useless words:\\n\")\n",
    "for x in sorted_indices[:100]:\n",
    "    print(vocab_df.iloc[x]['word'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following cell calculates the mutual information per document class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ignore warnings!\n",
      "pxs were calculated before. returning the result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sahba/programFiles/miniconda3/lib/python3.7/site-packages/scipy/sparse/_index.py:118: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray_sparse(i, j, x)\n",
      "/home/sahba/programFiles/miniconda3/lib/python3.7/site-packages/scipy/sparse/_index.py:118: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray_sparse(i, j, x)\n",
      "/home/sahba/programFiles/miniconda3/lib/python3.7/site-packages/scipy/sparse/_index.py:118: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray_sparse(i, j, x)\n",
      "/home/sahba/programFiles/miniconda3/lib/python3.7/site-packages/scipy/sparse/_index.py:118: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray_sparse(i, j, x)\n",
      "/home/sahba/programFiles/miniconda3/lib/python3.7/site-packages/scipy/sparse/_index.py:118: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray_sparse(i, j, x)\n",
      "/home/sahba/programFiles/miniconda3/lib/python3.7/site-packages/scipy/sparse/_index.py:118: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray_sparse(i, j, x)\n",
      "/home/sahba/programFiles/miniconda3/lib/python3.7/site-packages/scipy/sparse/_index.py:118: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray_sparse(i, j, x)\n",
      "/home/sahba/programFiles/miniconda3/lib/python3.7/site-packages/scipy/sparse/_index.py:118: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray_sparse(i, j, x)\n",
      "/home/sahba/programFiles/miniconda3/lib/python3.7/site-packages/scipy/sparse/_index.py:118: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray_sparse(i, j, x)\n",
      "/home/sahba/programFiles/miniconda3/lib/python3.7/site-packages/scipy/sparse/_index.py:118: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray_sparse(i, j, x)\n",
      "/home/sahba/programFiles/miniconda3/lib/python3.7/site-packages/scipy/sparse/_index.py:118: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray_sparse(i, j, x)\n",
      "/home/sahba/programFiles/miniconda3/lib/python3.7/site-packages/scipy/sparse/_index.py:118: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray_sparse(i, j, x)\n",
      "/home/sahba/programFiles/miniconda3/lib/python3.7/site-packages/scipy/sparse/_index.py:118: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray_sparse(i, j, x)\n",
      "/home/sahba/programFiles/miniconda3/lib/python3.7/site-packages/scipy/sparse/_index.py:118: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray_sparse(i, j, x)\n",
      "/home/sahba/programFiles/miniconda3/lib/python3.7/site-packages/scipy/sparse/_index.py:118: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray_sparse(i, j, x)\n",
      "/home/sahba/programFiles/miniconda3/lib/python3.7/site-packages/scipy/sparse/_index.py:118: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray_sparse(i, j, x)\n",
      "/home/sahba/programFiles/miniconda3/lib/python3.7/site-packages/scipy/sparse/_index.py:118: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray_sparse(i, j, x)\n",
      "/home/sahba/programFiles/miniconda3/lib/python3.7/site-packages/scipy/sparse/_index.py:118: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray_sparse(i, j, x)\n",
      "/home/sahba/programFiles/miniconda3/lib/python3.7/site-packages/scipy/sparse/_index.py:118: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray_sparse(i, j, x)\n",
      "/home/sahba/programFiles/miniconda3/lib/python3.7/site-packages/scipy/sparse/_index.py:118: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray_sparse(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "#calculates the p(X=xi) for all words\n",
    "def create_px():\n",
    "    global pxs_initialized\n",
    "    if not pxs_initialized:\n",
    "        print('generating all pxs this takes a few seconds')\n",
    "        for i in range(61188):\n",
    "            pxs[i] = sparse_training_data[:,i].sum()/TOTAL_VOCAB\n",
    "        pxs_initialized = True\n",
    "        print('pxs calculation complete!')    \n",
    "    else:\n",
    "        print('pxs were calculated before. returning the result')\n",
    "        \n",
    "# calculates the mutual information for all categories using the formula\n",
    "# MI = P(x,y) + log(p(x,y)/(p(x).p(y)))\n",
    "def calc_mutual():\n",
    "    create_px()\n",
    "    mutual_info = sparse_training_data.copy()\n",
    "    mutual_results = sparse.csr_matrix(np.zeros((21,61188)), dtype=np.float32)\n",
    "    non_zero_dict={}\n",
    "    for i in range(1,21):\n",
    "        row = mutual_info[i]\n",
    "        total_words = row.sum()\n",
    "        # print(row.shape)\n",
    "        non_zeros = mutual_info[i].nonzero()[1]\n",
    "        non_zero_dict[i] = non_zeros\n",
    "        # p(x|y)\n",
    "        pxgy = row.multiply(1/total_words)\n",
    "        pxy = pxgy.multiply(prior_counts[i])\n",
    "        pxgy[0, non_zeros] = np.log1p(pxgy[0,non_zeros].multiply(1/pxs[non_zeros]))\n",
    "        mutual_results[i, non_zeros] = pxy[0, non_zeros] + pxgy[0, non_zeros]\n",
    "    return mutual_results\n",
    "\n",
    "def print_mutual_results(mutual_results, vocab_df, doc_class_df, top_words=5):\n",
    "    results_dense =  mutual_results.todense()\n",
    "    best_words=[\"x\"] * top_words\n",
    "    worst_words = [\"x\"] * top_words\n",
    "    for i in range(1, 21):\n",
    "        row_dense = results_dense[i]\n",
    "        arg_maxes = row_dense.argsort()\n",
    "        print(doc_class_df.iloc[i-1]['doc_class'])\n",
    "        best_indices = arg_maxes[0,-top_words:][::-1]\n",
    "        worst_indices = arg_maxes[0,:top_words]\n",
    "        for ii in range(top_words):\n",
    "            best_index = best_indices[0,ii]\n",
    "            worst_index = worst_indices[0,ii]\n",
    "            best_words[ii] = vocab_df.iloc[best_index].word\n",
    "            worst_words[ii] = vocab_df.iloc[worst_index].word\n",
    "        print('most useful words')\n",
    "        print(best_words)\n",
    "        print('least useful words')\n",
    "        print(worst_words)\n",
    "\n",
    "print(\"ignore warnings!\")\n",
    "mutual_results = calc_mutual()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The foloowing cell analyzes the mutual information calculations per document class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 alt.atheism\n",
      "most useful words\n",
      "['darice', 'buphy', 'bobbe', 'beauchaine', 'mozumder']\n",
      "least useful words\n",
      "['vijay', 'elaine', 'magnetometer', 'typ', 'jjj']\n",
      "2 comp.graphics\n",
      "most useful words\n",
      "['nfotis', 'radiosity', 'siggraph', 'pov', 'rayshade']\n",
      "least useful words\n",
      "['vijay', 'scuttle', 'definetly', 'rectifies', 'chops']\n",
      "3 comp.os.ms-windows.misc\n",
      "most useful words\n",
      "['ashok', 'louray', 'vgalogo', 'qw', 'rlk']\n",
      "least useful words\n",
      "['vijay', 'recommending', 'coords', 'microwaves', 'surveyors']\n",
      "4 comp.sys.ibm.pc.hardware\n",
      "most useful words\n",
      "['fasst', 'jmarttila', 'usma', 'rll', 'fdisk']\n",
      "least useful words\n",
      "['vijay', 'emisions', 'eaton', 'woodard', 'juhan']\n",
      "5 comp.sys.mac.hardware\n",
      "most useful words\n",
      "['adb', 'iivx', 'bmug', 'lciii', 'iisi']\n",
      "least useful words\n",
      "['vijay', 'demondulator', 'downconversion', 'ackermann', 'inverting']\n",
      "6 comp.windows.x\n",
      "most useful words\n",
      "['argv', 'oname', 'ndet', 'xdm', 'args']\n",
      "least useful words\n",
      "['vijay', 'rafters', 'entrances', 'nmw', 'furnace']\n",
      "7 misc.forsale\n",
      "most useful words\n",
      "['keown', 'punisher', 'liefeld', 'sabretooth', 'wolverine']\n",
      "least useful words\n",
      "['archive', 'poeldvere', 'jakobi', 'estonia', 'conductance']\n",
      "8 rec.autos\n",
      "most useful words\n",
      "['buick', 'infiniti', 'corvette', 'opel', 'geico']\n",
      "least useful words\n",
      "['etrbom', 'recchi', 'fedyk', 'galley', 'eklund']\n",
      "9 rec.motorcycles\n",
      "most useful words\n",
      "['blaine', 'motorcycling', 'cookson', 'countersteering', 'biker']\n",
      "least useful words\n",
      "['vijay', 'propranolol', 'psychogenic', 'lungs', 'inmet']\n",
      "10 rec.sport.baseball\n",
      "most useful words\n",
      "['hirschbeck', 'mattingly', 'rbi', 'alomar', 'pitcher']\n",
      "least useful words\n",
      "['vijay', 'inkjets', 'downloadable', 'cablevision', 'dissimilar']\n",
      "11 rec.sport.hockey\n",
      "most useful words\n",
      "['ahl', 'bruins', 'nyr', 'leafs', 'nhl']\n",
      "least useful words\n",
      "['vijay', 'chiggers', 'affliction', 'gainesville', 'chigger']\n",
      "12 sci.crypt\n",
      "most useful words\n",
      "['cryptographic', 'plaintext', 'denning', 'crypt', 'ripem']\n",
      "least useful words\n",
      "['vijay', 'psychiatric', 'enacted', 'neurology', 'neurologist']\n",
      "13 sci.electronics\n",
      "most useful words\n",
      "['deaddio', 'capacitors', 'bubblejets', 'cmkrnl', 'adcom']\n",
      "least useful words\n",
      "['archive', 'nfpa', 'schwan', 'vacate', 'inspectors']\n",
      "14 sci.med\n",
      "most useful words\n",
      "['antibiotic', 'antibiotics', 'hicnet', 'dyer', 'candida']\n",
      "least useful words\n",
      "['vijay', 'cryptophone', 'cylink', 'laissez', 'blames']\n",
      "15 sci.space\n",
      "most useful words\n",
      "['ssto', 'prb', 'nsmca', 'baalke', 'orbiter']\n",
      "least useful words\n",
      "['vijay', 'keyspaces', 'disctribution', 'usenetters', 'lawfulness']\n",
      "16 soc.religion.christian\n",
      "most useful words\n",
      "['ahmadiyya', 'arsenokoitai', 'jayne', 'clh', 'athos']\n",
      "least useful words\n",
      "['archive', 'casserole', 'tlu', 'gic', 'ethridge']\n",
      "17 talk.politics.guns\n",
      "most useful words\n",
      "['shotguns', 'rutledge', 'thomasp', 'kratz', 'homicides']\n",
      "least useful words\n",
      "['vijay', 'slogans', 'shiriff', 'speculates', 'selectively']\n",
      "18 talk.politics.mideast\n",
      "most useful words\n",
      "['gaza', 'serdar', 'israelis', 'argic', 'istanbul']\n",
      "least useful words\n",
      "['vijay', 'redpoll', 'depew', 'corrosive', 'eichener']\n",
      "19 talk.politics.misc\n",
      "most useful words\n",
      "['schnopia', 'locutus', 'hendricks', 'steveh', 'stephanopoulos']\n",
      "least useful words\n",
      "['archive', 'behavioural', 'jhan', 'dgbt', 'vunerable']\n",
      "20 talk.religion.misc\n",
      "most useful words\n",
      "['caligiuri', 'mcconkie', 'zoroastrians', 'zarathushtra', 'royalroads']\n",
      "least useful words\n",
      "['vijay', 'beersheba', 'pasture', 'derby', 'sscl']\n"
     ]
    }
   ],
   "source": [
    "vocab_df = pd.read_csv('../res/vocabulary.txt', sep='\\n', header=None, names=[\"word\"])\n",
    "doc_class_df = pd.read_csv('../res/newsgrouplabels.txt', sep='\\n', header=None, names=[\"doc_class\"])\n",
    "#loading\n",
    "print_mutual_results(mutual_results, vocab_df, doc_class_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "formula from the proj2 PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def multinomial_naive_bayes(row, row_total_words, beta, debug_prints = False)->int:\n",
    "    if debug_prints: print(row_total_words, row)\n",
    "\n",
    "    max_prob_class = [float('-inf'), -1]\n",
    "    for doc_label in range(1, 21):\n",
    "        map_denom = sparse_training_data[doc_label].sum() + (beta * TOTAL_VOCAB)\n",
    "        running_sum = 0\n",
    "        for word_i, num_words_at_i in row:\n",
    "            running_sum += np.log2((sparse_training_data[doc_label, word_i] + beta)/map_denom)\n",
    "        posterior = np.log2(prior_counts[doc_label]) + running_sum\n",
    "        if posterior > max_prob_class[0]:\n",
    "            max_prob_class[0] = posterior\n",
    "            max_prob_class[1] = doc_label\n",
    "\n",
    "    if debug_prints: print(max_prob_class)\n",
    "    return max_prob_class[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def bernoulli_naive_bayes(row, row_total_words, beta, debug_prints = False)->int:\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def test_training(bayes_function, beta):\n",
    "    sparse_matrix = sparse.load_npz('../res/nb_training_data.npz')\n",
    "    training_data_coo = sparse_matrix.tocoo()\n",
    "\n",
    "    row_total_words = training_data_coo.A.sum(axis=1)\n",
    "    correct = 0\n",
    "    row = []\n",
    "    row_i = 0\n",
    "    for row_i, word_i, val in zip(training_data_coo.row, training_data_coo.col, training_data_coo.data):\n",
    "        if word_i != 61188:\n",
    "            row.append((word_i, val))\n",
    "        else:\n",
    "            classification = bayes_function(row, row_total_words[row_i] - val, beta=b)\n",
    "            correct += 1 if classification == val else 0\n",
    "            row.clear()\n",
    "            if not row_i % 500:\n",
    "                print('At row:', row_i)\n",
    "    print(\"Finished\")\n",
    "    print(f\"accuracy: {(correct / row_i) * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification and Writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def test_and_write(bayes_function, write_path, beta):\n",
    "    sparse_matrix = sparse.load_npz('../res/nb_testing_data.npz')\n",
    "    testing_data_coo = sparse_matrix.tocoo()\n",
    "    with open(write_path, 'w') as out_stream:\n",
    "        out_stream.write(\"id,class\\n\")\n",
    "    \n",
    "        row_total_words = testing_data_coo.A.sum(axis=1)\n",
    "        row_offset = 12000\n",
    "        current_row = 12000\n",
    "        row = []\n",
    "        for row_i, word_i, num_words_at_i in zip(testing_data_coo.row + row_offset, testing_data_coo.col, testing_data_coo.data):\n",
    "            if row_i == current_row:\n",
    "                row.append((word_i, num_words_at_i))\n",
    "            else:\n",
    "                predicted_label = bayes_function(row, row_total_words[row_i - row_offset], beta=b)\n",
    "                out_stream.write(f'{row_i},{predicted_label}\\n')\n",
    "                row.clear()\n",
    "                current_row = row_i\n",
    "                if not current_row % 500:\n",
    "                    print('At row:', current_row)\n",
    "    print(\"File written\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "- multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "b = .0041 # BETA: Tried -> 1/TOTAL_VOCAB, .00001, .0001, .001, .01, .1, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "print('beta:', b)\n",
    "test_training(multinomial_naive_bayes, beta=b)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', (stop - start) / 60, 'minutes.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "beta: 0.0041\n",
      "At row: 12500\n",
      "At row: 13000\n",
      "At row: 13500\n",
      "At row: 14000\n",
      "At row: 14500\n",
      "At row: 15000\n",
      "At row: 15500\n",
      "At row: 16000\n",
      "At row: 16500\n",
      "At row: 17000\n",
      "At row: 17500\n",
      "At row: 18000\n",
      "At row: 18500\n",
      "File written\n",
      "Time:  26.004021093333332 minutes.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "print('beta:', b)\n",
    "file_path = '../results/multinomial_NB_b' + str(b)[(2 if b < 1 else 0) :] +'_results.csv'\n",
    "test_and_write(multinomial_naive_bayes, file_path, beta=b)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', (stop - start) / 60, 'minutes.') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEPCAYAAABRHfM8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXxU1fn48c+TZCYL2YAkBAIhyL4LhB0UpUpdUJSKW4GIiqBoLT+pWq3V2q9aNwp1qyiitSq4V1FRUVFAliAICgIiYQm7yp6Q7fz+uBNIJpNkkszcmUme9+t1XzNz75k5z4ThPvfce885YoxBKaWUqk5YoANQSikVGjRhKKWU8oomDKWUUl7RhKGUUsormjCUUkp5RROGUkopr0QEOgB/SUpKMhkZGYEOQymlQsqqVasOGGOSPW2zNWGIyBnAbUAfoAVwjTFmTjXv6Q48AfQDfgH+DdxvqulAkpGRQXZ2ti/CVkqpBkNEtlW2ze5TUrHAd8AfgLzqCotIPPAJsBfoC9wCTAOm+jFGpZRSHtjawjDGfAB8ACAic7x4y9VADDDeGJMHfCcinYGpIvJ4da0MpZRSvhPsF70HAl+5kkWpBVinszICEpFSSjVQwZ4wUrFOR5W1t8y2ckRkoohki0j2/v37/R6cUko1JMGeMADcTztJJesxxjxrjMk0xmQmJ3u8yK+UUqqWgj1h7KFiSyLF9eje8vCNtfNgeje4N9F6XDvPL9UopVSoCfaE8TUwVESiyqw7B9gF5Pi8trXz4L1b4NAOwFiP792iSSOU6QGAUj5jdz+MWKCd62UYkC4ipwO/GGO2i8iDQD9jzHBXmVeAvwJzROTvQAfgDuA+v9whtfBvUOh2t29hHsz/f/BrDiCuE2ICIiBhp55X9yhhpX8EL98TVsk2T59RWVlPj9Qibrf3e122uvhrEneYh/dXU/a7N2H+1FP/pqUHAAA9xtTopxEQa+dZv8lDOyGhJQy/JzTiVvWW2HlnqogMAz73sOlFY0yW61bbYcaYjDLv6Q48idVx71fgGeBv1SWMzMxMU+OOe/cm4uHSiKp3BGKaQrjDWsIcEO6E8Igyzx0QFnHq+clylT13f7/bZ1X7frfP2jgfPvozFJU5gHFEw8iZ/ksamqAUICKrjDGZHrfV164MtUoY07u5Tke5SWgJt3wLGDDG7bHEw7qyj9SgrNujKXF7f3VlPW2jBmWr+nxvy7p/x6ri9/bvQc3jNiXw2f2V/1tnToDiQmspKazieQEUF1X+vLjAel36b+VvEgaJ6RARDY6oKh5dS5VlyjxuWWgli6L8U3XVJUFp8glZVSWMejuWVK0Mv8c6ZVHodlQ3/K/WEaMKLavmVHIA0AounO7bukqK65Zw3BPW/EoGMzAl0LKf1fIozLd28PmHoWif9bstyi//WJcWc2EevDMJls6EyHhwxkJkHES6Hp1xHl7HwralsOgfp5JPqJ0KVJXSvWBZpT9mPTKqHyo9ALjH93WFhVsLUdUW9cri6ZUnu9GzvPsMY6yEVJpAivJdSSav4uMbEzx/RkkxxLeEE0fg6B74eTOcOGq9Lqp2dJ9TCvOs/1f6fymkacJw12OM/qjri1A+APBFshOBiEhrqc4nf608QV31muf3FBdBwZFTCaTgKJw4DC+P9lz+0A7IXQVpfbz/DiqoaMJQ9VuoHgDYnexqk6DCIyC6sbWUldDKc/JBYNbZ0Px06xpS99+Bs5FPwlf20IveSimLry5Ul/Znck8+v33Iuj6z8nnYvwEiE6DnFVbySOnku++h6kTvklJK2auq5GMMbF8G2c/D+net6yytB1uJo/NFEOEMbOwNnCYMpVRwOnYAVv8Hsl+Ag9ugUTL0Ggt9sqBx60BH1yBpwlBKBbeSEtjymdXq2PSR1Qppfw5kXms9hoUHOsIGQ/thKKWCW1gYtP+NtRzcAd+8CN+8BK9eDgnp0Ge81fKIaxboSBs0bWEopYJTcSH8MN9qdWz90hqqpfNIq9WRMeTU2GLKp7SFoZQKPeEO6DrKWg5stq5zrPkvfP82JHW0LpL3vAKiEwMdaYOhLQylVOgozIPv3rJaHbmrrHGwuo+2Wh1pvQMdXb2gLQylVP3giIZeV1vLrjWQPRvWvQ6rX4YWvaxWR7ffgTMm0JHWS9rCUEqFtvxD8O1cq9Wx/werQ+DpV1rJI7ljoKMLOXpbrVKq/jMGtn9t9SRf/6418m/GUMi8BjqN1A6BXtJTUkqp+k8EWg+ylqMPWR0CV71gjcTbKAV6uzoEJqYHOtKQpS0MpVT9VVJiTQ618nnYvMDVIfBc6HsttPuNdgj0QFsYSqmGKSzM6ine/pzyHQJfGWN1CMzMsjoExqYEOtKQoC0MpVTDUlwIP7xvtTpyvrLmUe880mp1tB5s3XUVinOo+Ii2MJRSqlS4A7peYi37N1nXOdb8F75/C2JT4fjP1gVz0Oll3YQFOgCllAqY5A7w2wdh6g9w8ZOQ98upZFGqdHpZpQlDKaVwxkCv31unqzw5tNPeeIKUJgyllCqV0LJm6xsYTRhKKVVq+D3W8CNlVTe3eQOiCUMppUr1GAMjZ0JCq1PrMq/TC94uepeUUkqV1WOMtRQXwj+7w97vAh1R0NAWhlJKeRLugL7XwU+fw74NgY4mKGjCUEqpyvS5BiKiYPkzgY4kKGjCUEqpyjRqap2e+nYuHP8l0NEEnCYMpZSqSv9JUJQHq+YEOpKA04ShlFJVadYV2pwJK5+rvGNfA6EJQymlqjNgMhzOhQ3/C3QkAaUJQymlqtN+BDRuA8sa9sVvTRhKKVWdsDDrWsbOFbBzVaCjCRhNGEop5Y3TrwJnHCx/OtCRBIwmDKWU8kZUvDUv+Pdvw+HdgY4mIDRhKKWUt/pNhJJiyH4+0JEEhCYMpZTyVpM20PE8yJ4NhfmBjsZ2mjCUUqomBky2pnFd93qgI7Gd7QlDRG4Uka0iki8iq0RkaDXlx4jIGhE5LiLbRGSaXbEqpVQFGUOhWTdY9jQYE+hobGVrwhCRy4EZwANAL2Ap8KGIpFdS/jzgFeBZoBtwI/BHEZliT8RKKeVGxLrFdt/3kPNVoKOxld0tjKnAHGPMLGPMBmPMzcBuYHIl5ccC7xljnjLG/GSMmQ88CNwuImJTzEopVV73yyCmaYPryGdbwhARJ9AH+Nht08fAoEreFgm4X1nKA1oCrX0aoFJKecsRZQ19vvED+OWnQEdjGztbGElAOLDXbf1eILWS9ywARonIuSISJiIdgP/n2tbcvbCITBSRbBHJ3r9/v6/iVkqpivpeB2HhsGJWoCOxTSDuknK/SiQe1pWaBcwE3gUKgGXAa65txRU+2JhnjTGZxpjM5ORkH4WrlFIexDeHrpfAN/+B/MOBjsYWdiaMA1g7effWRAoVWx0AGMvtQCzWKahUYIVrc45/wlRKKS/1nwwFR2DNK4GOxBa2JQxjTAGwCjjHbdM5WHdLVfXeYmNMruszrgS+Nsbs80+kSinlpZZ9oGU/awrXkpJAR+N3dp+SehzIEpHrRKSziMwAWgDPAIjIgyKysLSwiCSJyGRX2dNd5S8DbrU5bqWU8mzAJPh1K2xeEOhI/M7WhGGMmYu1s78bWAMMAc43xmxzFWkOtHV72zhgJbAE6AoMM8asQCmlgkHniyA+zerIV89F2F2hMeYp4KlKtmW5vT4ADLQhLKWUqp1wh3XH1ML7YO/31pSu9ZSOJaWUUnXVJwsioq1rGfWYJgylFADvrM5l8EOf0eaO+Qx+6DPeWZ0b6JBCR0wT6Hk5rJ0Hx34OdDR+owlDKcU7q3O586115B7MwwC5B/O48611mjRqov8kKMqHVS8EOhK/sf0ahlLKO++szuWRBRvZdTCPFonRTBvRkVG90mr9eSUlhiP5RRzMK+Dg8UIO5hVyKK+QQ8cLeHjBRvIKy/eFzSss5t7/fU+UI4zGMU6aNLKWxBgn4WFVD+Xm69hDQkpnOO0sWPkcDP6DdW2jntGEoVQQKj3iL92Jlx7xA5zfvTkH8wo4nFdo7fhdO/+DxwusBJB3at2h4wWnEkNeYY1H4z6YV8ikl78pt04EEqIdNHElkcaNnDSJcT02crD1wDHeXJVLQXFJhdjrfdIYMBleGQPr34Xuvwt0ND4npp6O556ZmWmys7MDHYYKMLuOdI0xFJUYThSVcKKwmHzX44mikpPrTj4vKuZEYZnnRSWu19bz/MJi3l6dy/GCCqPfVDmODpzamSdGO0iIcVqP0Q4SY8qvS4w5tT4h2snFTyxm16GKM8ilxkfxfFYmvx4r5JfjBfx6rICfj1mPpa9/cS2/Hi+gsLjy6NISo1lyx9m1+OuGkJISeCITohvD9QurLx+ERGSVMSbT0zZtYah6qbC4hLkrd3D/++s5UXTqSPdPb6xlzY5f6dkqsfxOu5IdeH6ZHXl1ZUvqeOzlCBciI8KJjAjzmCzAShb/75wO1o6+zM4/MdpJQrSDuKgIwqo5XeTJn37bqVyLBiDaEc4d53Wia4sErz7DGMPRE0X0uPdjj0lt18G8GscVcsLCrGsZH06DHSuhVd9AR+RTmjBU0CkuMRzNL+JwfiFHyjweKX2dV8iRE9brw6Wv80+9PpJfSH6h52EaCopLmLN0G7CtwrYwgSiHtcMufYyMCCfSEUZkRBjRjnASox2u16Xbw4h0lHlepvzJMq7yUeXeV76cMyKs3HWBwQ99Rq6HHWxaYjQ3D2/vs791qdJWV11aYyJCXJSDFonRHmOPCBd+3HeEdilxPos7KJ1+JXx2Pyx/WhOGUlUxxnCsoNjaeeeV2cmX2ZkfcdvJl08KRRw9UVRtPVGOMOKiHMRHRRAXZR1ZpyVGEx/teh0ZwWOfbPL4XgE+v21YhR1/RHjw3DQ4bURHj0f800Z09Fudo3ql+eR0nafYneGCIzyMC2Yu5o7zOjF+YEatWkIhITIOeo+z+mQc3gXxLQIdkc9owlAnGWPILywpd6RedidfMQmUP/o/nFfI0RNF1Z6acYQL8a6dfFyUg/joCE6LjS33ujQJxEdFuMq6Xkc7iI2MwBlR/c79tZU7PB7ptkiMJiOpUW3/TLbwxRF/oFQW+6B2TbnjzXXc9956Pt2wl0d+15MWidEBjtZP+l0Py56y7pgafk+go/EZvehdjxQUlXg4Yrd28mWP4K3n7q+tslVdtATrtM2pnXmZnb5rZ269Lr+TjyuzLT7KQWREGHbMsOt+pxFYR+kPXto9JHa89ZExhtdc15bCw4T7L+7Gxae3sOX3YLvXroZtS2HqenCETmLUi941EKj7x4tLTIWdfVWnbTyd4im9uFuV2MiIcqdxkuMiOS25UZkdf/mdfvmjfQcxzvCQ+c8dykfp9ZWIcGW/dAa1bcrUed9y69w1fLJhL/83qhuJMc5Ah+dbAybDD+9bvb/7jA90ND6hLYwyantEWlJiOFZQ8Wi9dEd+2LWTr+oUz7FK7oopK9oR7nbE7n7aJsLz0b9rpx8bGVFthyul7FJcYnhm0Rb++ekmGsc4efh3PRjWMSXQYfmOMfDMUCgpghu/tu55DgFVtTA0YZRR2Z0psZERXNo7rZJTPNYdO9X9GZ3hYeVOzcRFRRAXWfEI3vMpHuvREUQXZZXyle9yD/HHuWvYvO8ovx+Qzp/P70yMs56c/Fj9X3j3Rhj3Lpw2LNDReEUThpfa3DG/0k5RiTGOSnfyZU/xVLxoaz1GOcLr/qWUqqfyC4t5dMFGnl+ylYymjXh8TE96pTcOdFh1V5gP07tCy75w1WuBjsYreg3DS5XdP56WGMWSO4YHICKlGoYoRzh3X9iF4Z2bcdvr3/K7Z77mpmFtuXl4+9BuWTuiIHMCfPkI/LwFmrrPDxdaQvhfwvemjehItFtLwLr3vVOAIlKqYRnYtikf3jqUi09vwczPfuTSp5by476jgQ6rbvpeC2ERsOLZQEdSZ14lDBEZJSL1/pzKqF5pPHhpd9ISoxGsXrV6C6ZS9oqPcvD4mNN5+ure7Pz1OBfM/IoXlmylpK5jrwRKXCp0uxRWvwz5hwIdTZ14dQ1DRI4BR4AXgdnGmI3+DqyuGmI/DKXqm31H8rn9jbV8vnE/Q9ol8chlPWieEDp9Gk7atRqeHQYjHoSBNwY6mipVdQ3D21NSqcBfgTOB9SKyWESuEZHg7i6rlAppKXFRzM7qywOXdOeb7b8yYvqXvLsmBCd1atELWg2AFf+GkupvoQ9WXiUMY8wRY8y/jTEDgO7AcuBBYLeIzBKRAf4MUinVcIkIV/VP54NbhtIuJZY/vLaGKa98w8HjBYEOrWYGTIJfc2DTR4GOpNZqfNHbGLMemA48CziBy4GvRGS5iPTwcXxKKQVARlIj5t0wkGkjOvLRd3sY8c8vWbRpf6DD8l6nkRDfEpY9HehIas3rhCEiDhEZIyIfAVuBs4FJQDOgNbAJmOuXKJVSCogID+Oms9rxzk2DiY9yMH72Cu559zvyvBgpIeDCI6xBCXO+gj3fBTqaWvH2Lql/AbuBJ4H1QE9jzBBjzBxjTJ4xZhdwF+C/sZeVUsqlW1oC7908hGuHtOGlr7dxwcyvWLPjYKDDql7vceCIsebKCEHetjC6AFOANGPMVNdpKXe7gLN8FplSSlUhyhHOXy7swivX9ye/sJjRTy/l8U82UVhc/SCcARPTBHpeAWtfh2MHAh1NjXl70Xu4MeY1Y0ylV5mMMUXGmEW+C00ppao3qG0SH956Bhf3bMHMhZsZ/XSQd/brPwmKT0D2C4GOpMa8PSX1fyIyycP6SSJyv+/DUkop7yVEO3j88tN56urebP/F6uw3J1g7+yV3hLbDrcmVikLrTi9vT0mNBVZ7WL8KGOe7cJRSqvbO796cj289g4Ftm3Lve+sZ/8IK9hzKD3RYFQ2YDEf3wPp3Ax1JjXibMFIAT/ev/Yx1l5RSSgWFlPgoXsjqy/9d0o3snF85d/qi4Ovs13Y4NG1vTeMaQiOGe5swtgNDPaw/A9jpu3CUUqruRISr+7fmwz8MpW0wdvYLC4P+N8Cub2DnykBH4zVvE8a/gekicr2ItHUtE4HHsDrwKaVU0MlIasTrNwzktnM7nOzs92WwdPbreSVEJlitjBDh7V1Sj2EljZlYHfQ2ATOAWcaYh/0XnlJK1U1EeBhTzm5/srPfuGDp7BcZC33Gwfr/waHQOFHjdU9vY8ydQBIwABgIJBtj7vBXYEop5Uulnf0mDD7V2e/bQHf26zcRMNYdUyGgRmNJGWOOGWNWGmNWGGOC+EZnpZSqKMoRzj0ju/DKdVZnv0ufXsr0QHb2S0yHThdafTIKjgcmhhqoyVhSZ4nIsyLykYh8VnbxZ4BKKeVrg9pZnf0u6tmCGQs387unl7Jlf4COgQdMhvyDsDb4h+LztuNeFvAhEAcMw7rFtjHQG2tsKaWUCikJ0Q6muzr7bXN19ntxaQ5vr9rJ4Ic+o80d8xn80Ge8s9rPt+SmD4TUHrD8maC/xTbCy3K3AVOMMc+JyBHgTmPMTyLyBKCnppRSIev87s3JbN2YP725lr/+73vCBEo7iOcezOPOt9YB+G+qZhEYcCO8Mwl++hzanu2fenzA21NSpwGfup6fAGJdz58Asnwck1JK2aq0s19CtAP30UTyCot5ZIGfZ6Xudik0SoFlz/i3njryNmH8jHU6CiAX6OZ63hSo0QS7InKjiGwVkXwRWSUinjoEli0/QkS+FpEjInJARN4VkQ41qVMppaojIhzOK/S4bdfBPP9WHhEJmRNg8wI48KN/66oDbxPGV8C5rufzgJki8gLwKvCJt5WJyOVY/TceAHoBS4EPRSS9kvJtgHdd9fcCfoOVoD7wtk6llPJWi0TPx7+VrfepzAkQ7rTm/Q5S3iaMKVjJAay5vB/Bal3MA66rQX1TgTnGmFnGmA3GmJuxJmaaXEn5PoAD65rJj8aYNa7624pIUg3qVUqpak0b0ZFoR3i5ddGOcKaNsGFuuLhm0G00rP4v5AXnZFDVJgwRiQCuKH1tjCkxxvzDGHORMeY2Y4xX30xEnFgJ4GO3TR8Dgyp5WzZQCFwnIuEiEgeMB1YaY0Jv9hGlVFAb1SuNBy/tTlqZFsWkYaf574K3u/6ToPAYrH7ZnvpqqNqEYYwpwmpROOpYVxIQDux1W78XSK2k7hzgHOA+rIvth4DuwIWeyovIRBHJFpHs/fuDZLwYpVRIGdUrjSV3nM13940gLjKCn/Yfs6/yFqdD+iDrtFRJ8M1T7u0pqWVYrQNfcL/RWDysszaIpALPAy8BfbH6gBwB5olIhdiNMc8aYzKNMZnJyck+Clcp1RDFRkYwpm8r5q/dbe+cGgMmwcHtsDH4LtV6mzBmAY+KyK0iMlREepddvPyMA0AxFVsTKVRsdZS6CThmjPmTMWa1MeZL4PfAmVR+GksppXwia1AGJcbwn2U59lXa8QJISA/KW2y9TRivABnA48AirGsLpYtXg7m75gNfhXWKqaxzsO6W8iQGK8mUVfq6RuNgKaVUTbVqEsM5XZrxyvLt9o1uGx4B/a6HbYth91p76vSStzvdNlUsp9WgvseBLBG5TkQ6i8gMoAXwDICIPCgiC8uUnw/0FpG/ikh7V2vmBWAHVvJRSim/mjC4Db8eL+QdO2ft6z0WHI2s4UKCiLfzYWyravG2MmPMXOBW4G5gDTAEOL/MZzQH2pYp/xlwFXAx1pziC7DumvqtMcbGK1FKqYaqX5smdGkez+zFWzF2jfUU3RhOvxLWvQ5Hg+cGHvHmDyAil1a13Rjzls8i8pHMzEyTnZ0d6DCUUvXAG6t2ctvr3/Kfa/sxtL1NN9Qc2AxPZMKwP8Ow2+2pExCRVcaYTE/bvB188I1K1pdmm/BKtiulVMgb2bM5D324gReW5NiXMJLaQ7tzIPt5GPJHiHDaU28VvD0lFVZ2AZxAf6whO87wZ4BKKRVokRHh/H5Aaz77YR8/2TlvxoBJcHQvfP+2fXVWoVZ3GhljiowxK4E/A6Ezg7lSStXS1f1b4wwPY87SHPsqbTsckjrCsqeCYq6Mut6aepAyF6mVUqq+So6L5KLTW/B69k4OHfc8qq3PiUD/G2D3Gtix3J46q+DtjHu93ZY+InIh8G+su5eUUqreu2ZwBnmFxczN3m5fpT2vgKgEq5URYN62MEo76JXtrPc/rIvdNRmtVimlQlbXFgkMOK0JLy7dRlFxiT2VOhtBnyzY8D4c3GFPnZWoSce90zjVWa81EGOMGWSM8fNUVEopFTwmDG5D7sE8Pl5f2YhGftD3eutx5Sz76vSgth33dhhjbByNSymlgsPwzs1IbxLD7MVb7as0sRV0Hgmr5kBB4Pose3sN4/9EZJKH9ZNE5H7fh6WUUsEpPEwYPyiD7G2/8u0OGyc6GjAZ8g/Bt6/ZV6cbb09JjcXzxe1VwDjfhaOUUsFvTGZLYiMjeGGJja2MVv2h+enW+FIlNl0/ceNtwkgBPA1o8jPQzHfhKKVU8IuLcnBZZkvmr9vN3sM2nZ0XgQE3woFN8NNn9tTpxtuEsR0Y6mH9GcBO34WjlFKhIWtQBkUlhpeXeT3+at11vQRimwVsrgxvE8a/gekicr2ItHUtE4HHgGf9F55SSgWn1k0b8ZvOzfjv8u3kF9o0V0aEE/peBz9+Avs32VNnGd7eJfUYVtKYCWxyLTOAWcaYh/0XnlJKBa8Jg9vwy7EC3rVzrow+10C405r322ZeDw1ijLkTSAIGAAOBZGPMHf4KTCmlgt2A05rQuXk8sxfn2DdXRmwydL8M1rwCeb/aU6eLt7fVpopIS2PMMWPMSmPMCmPMURFpKSJ60Vsp1SCJCBMGZ7Bx7xGWbvnZvor7T4LC4/DNf+yrE+9bGP8BzvOwfoRrm1JKNUgje7YgKdZpb0e+5j2g9RBYMQuKi2yr1tuE0Rf40sP6rwCPMzMppVRDEOUI5+r+rVn4wz62HrCxF/aASXBoO2ycb1uV3iaMCCDSw/qoStYrpVSDcfWAdBzhwhw7O/J1PB8S0229xdbbhLEcmOxh/U1YI9cqpVSDlRIXxcieLXh91U4O5dk0V0ZYOPS7AbYvhV1r7KnSy3J3AeNFZKmI3O9almANC/Jn/4WnlFKhYcLgNhwvKOb1bBuHIO89Fpyx1nAhNvC2H8YyrFtptwKXAqOBn1zrYvwWnVJKhYhuaQn0a9OEF5bk2DdXRlQCnH4VfPcmHPH/cOs16YfxrTHmamNMV+BcrM57bwML/BWcUkqFktK5Mj7dYONcGf1ugOICyJ7t96q8ThgiEi4il4jIfKyWxijgaaCdv4JTSqlQck6XZrRsHM3sxTn2VZrUDtqPgOznoeiEX6uqNmGISEcReQTYhTV21GpAgLHGmIeNMTbeFqCUUsErPEzIGpTBipxfWLfzkH0VD5gEx/bDd2/5tZoqE4aIfAUsAxKBMcaY04wxdwM29YFXSqnQMqZvKxo5w+2dK+O0syC5Eyx7Cvw4REl1LYyBwEvADGPMIr9FoZRS9UR8lIPLMlvx3tpd7LNzroz+k2DPWtj+td+qqS5hZGJ12vtKRFaLyB9FJNVv0SilVD0QkLkyelwOjhj4z6VwbyJM7wZr5/m0iioThjFmjTHmJqA58DhwMbDD9b4LRKSxT6NRSql6ICOpEcM7pdg7V8YP71t3SxXlAQYO7YD3bvFp0vC2H0a+MeY/xphhQGfgEeCPwB4R+dBn0SilVD0xYXAbfj5WwP++3WVPhQv/BiVuAxEW5lnrfcTr22pLGWN+dM2D0QoYAxT4LBqllKonBrZtSqfUOGYv3mrPXBmHKpktu7L1tVDjhFHKGFNsjHnXGHOxz6JRSql6wporow0/7DnC1z/ZMFdGQsuara+FWicMpZRSVbvo9BY0aeS0pyPf8HvAEV1+nSPaWu8jmjCUUspPohzh/L5/Ogt/2EuOv+fK6DEGRs6EhFaAWI8jZ1rrfSTCZ5+klFKqgt8PaM3Ti7YwZ2kO917U1b+V9Rjj0wThTlsYSinlRynxUYzs0YLXs3dwON+muTL8RBOGUkr52TWD23CsoJh5K22cK8MPNGEopZSfdW+ZQN+MxsxZmkNxSegOxWd7whCRG0Vkq4jki8gqERlaRdl7RcRUsqTYGbdSStXFhLSY6kYAABe9SURBVMFt2PlrHp+st3GuDB+zNWGIyOXADOABoBewFPhQRNIrecujWMOSlF0WAV8YY/b5P2KllPKNc7o0Iy0x2t5RbH3M7hbGVGCOMWaWMWaDMeZmYDcw2VNhY8xRY8ye0gVwAEOBWfaFrJRSdRcRHkbWoAyWb/2F73JtnCvDh2xLGCLiBPoAH7tt+hgY5OXHXAscBN70YWhKKWWLMX1bEeMM54UlOYEOpVbsbGEkAeGA+wm8vUC1Q6aLSBgwAXjJGOPfeQiVUsoPEqIdXNanJe99u4t9R2yaK8OHAnGXlPstAuJhnSfnYw14+FxlBURkoohki0j2/v376xCiUkr5R9bgNhQUl/DfZdsDHUqN2ZkwDgDFVGxNpFCx1eHJ9cBSY8z3lRUwxjxrjMk0xmQmJyfXPlKllPKTNifnythm31wZPmJbwjDGFACrgHPcNp2DdbdUpUSkBXABerFbKVUPTBjShgNHC3jPrrkyfMTuU1KPA1kicp2IdBaRGUAL4BkAEXlQRBZ6eN8E4Bjg2/kGlVIqAAa1bUrHZnHMXpJjz1wZPmJrwjDGzAVuBe4G1gBDgPONMaUT3zYH2pZ9j4gI1t1R/zXGHLcxXKWU8gsR4ZrBGWzYfZhlP/0S6HC8ZvtFb2PMU8aYDGNMpDGmjzHmyzLbsowxGW7ljTGmjTHmRrtjVUopfxnVK43GMY6Q6sinY0kppVQARDnCubp/az7ZsJftP4fGyRNNGEopFSBjB7YmXIQ5S3MCHYpXNGEopVSANIuP4sIezZmXvYMjITBXhiYMpZQKoAlD2nD0RBGvZ+8MdCjV0oShlFIB1KNlIpmtQ2OujAY5p3dJSQkHDhzg4MGDFBeHVk9LVbnw8HASExNJSkoiLEyPhVTomDCkDTf+9xsWbtjLuV2rHVovYBpkwti5cyciQkZGBg6HA6urhwplxhgKCwvZu3cvO3fuJD29silWlAo+57rmypi9ZGtQJ4wGeRh27Ngx0tLScDqdmizqCRHB6XSSlpbGsWPHAh2OUjUSER7G+EGtWfbTL3y/K3jnymiQCQPQUxb1lP67qlB1eWY60Y7gnitD/3cppVQQSIhx8Ls+Lfnfml0cOBqcU/5owlBKqSCRNTgjqOfK0IShai07OxsRIScnJ9ChKFUvtE2O5ayOyfxn2TZOFAXfHZyaMELIsGHDmDJlik8/84svvkBEOHDggE8/tzL++A5K1SfWXBkneP/b3YEOpYIGeVutr7yzOpdHFmxk18E8WiRGM21ER0b1Sgt0WEqpEDakXRLtU2KZvWQrl/ZOC6o7ObWFUUvvrM7lzrfWkXswDwPkHszjzrfW8c7qXL/Ul5WVxaJFi3jyyScRkXKngtavX88FF1xAXFwcKSkpXHnllezZs+fke9etW8fw4cOJj48nLi6Onj178vnnn5OTk8NZZ50FQHJyMiJCVlZWpTF89NFHdOrUiaioKIYOHcqmTZvKbf/555+58soradmyJdHR0XTt2pUXXnih2u9QXFzMtddeS5s2bYiOjqZ9+/Y8/PDDlJSU+O4PqFSIEBEmDGnD97sOs2JrcM2VoS0Ml/ve+571uw57XX719oMUFJffoeUVFvOnN9by6grvLlh1aRHPX0d29arsjBkz2LRpE506deKBBx4ArJ387t27OeOMM7j22mt59NFHKSws5K677uKiiy5i2bJlhIWFcdVVV9GzZ09WrFhBREQE69atIyoqilatWvHmm28yevRovv/+e5o0aUJ0dLTH+nfs2MGoUaO4/vrruemmm1i7di1Tp04tVyY/P5/evXtz++23Ex8fz6effsoNN9xAeno6w4cPr/Q7lJSUkJaWxrx580hOTmbFihVMnDiRpk2bcu2113r191GqPrmkVxoPf/QDs5dspf9pTQMdzkmaMGrJPVlUt76uEhIScDqdxMTEkJp6qifo008/Tc+ePfnHP/5xct1LL71EkyZNyM7Opl+/fmzbto3bbruNTp06AdCuXbuTZZs0aQJASkoKSUlJldb/9NNPk56ezsyZMxEROnXqxKZNm/jLX/5yskxaWhrTpk07+XrixIl89tlnvPrqqwwfPrzS7xAeHs7f/va3k68zMjL45ptvePXVVzVhqAYpyhHOVf3TeeqLLWz/+TjpTWMCHRKgCeMkb4/0Sw1+6DNyD+ZVWJ+WGM3cGwb6KqxqrVq1ii+//JLY2NgK27Zs2UK/fv2YOnUq1113HS+++CLDhw9n9OjRJ5OHtzZs2MCAAQPKnU8dOLD89ywuLuahhx5i7ty55ObmcuLECQoKChg2bFi1n//MM8/w3HPPsW3bNvLy8igsLKR169Y1ilGp+mTsgAz+vegnXvw6h79c2CXQ4QB6DaPWpo3oSLQjvNy6aEc400Z0tDWOkpISLrjgAtasWVNu2bx5MxdeeCEA9957L+vXr2fUqFEsXbqUHj16MHv27BrV481E9Y8++iiPPfYY06ZNY+HChaxZs4ZRo0ZRUFBQ5fvmzp3LrbfeSlZWFgsWLGDNmjXceOON1b5PqfosNSGK87s3Z97KHRw9URTocABtYdRa6d1Qdt4l5XQ6K4yu27t3b+bNm0fr1q1xOByVvrd9+/a0b9+eW265hcmTJ/Pcc88xYcIEnE4nQLWj9nbp0oU333wTY8zJVsayZcvKlVm8eDEjR45k7NixgJVkNm3aRGJiYpXfYfHixfTv37/c7bZbtmypMh6lGoIJQ9rwv2938Ub2DrIGtwl0ONrCqItRvdJYcsfZbH3oApbccbbfb6nNyMhgxYoV5OTkcODAAUpKSrjppps4dOgQl19+OcuXL+enn37i008/ZeLEiRw5coS8vDxuuukmvvjiC3Jycli+fDmLFy+mSxeridu6dWtEhPnz57N//36OHj3qse5JkyaRk5PDrbfeysaNG3njjTd45plnypXp0KEDCxcuZPHixfzwww9MmTKFrVvLT3Dv6Tt06NCBb775hg8//JDNmzdz//33s2jRIv/8EZUKIae3SqR3eiIvLM2hJBjmyjDG1MulT58+pjLr16+vdFsw27hxoxkwYICJjo42gNm6dasxxphNmzaZ0aNHm8TERBMVFWU6dOhgpkyZYk6cOGFOnDhhrrzySpOenm6cTqdp3ry5uf76682hQ4dOfu7f/vY3k5qaakTEjB8/vtL633//fdOhQwcTGRlpBg0aZF5++eVycfzyyy/mkksuMbGxsSY5OdlMmzbNTJ482Zx55plVfocTJ06YCRMmmMTERJOQkGAmTJhg7rvvPtO6deta/Z1C9d9XKU/e+zbXtL79ffPJ93tsqQ/INpXsV8V4cW46FGVmZprs7GyP2zZs2EDnzp1tjkjZRf99VX1SVFzCGQ9/TkZSI165foDf6xORVcaYTE/b9JSUUkoFsYjwMMYNymDplp/ZsNv7vmL+oAlDKaWC3BV9W7nmythafWE/0oShlFJBLjHGyeg+abwT4LkyNGEopVQIyBrUhoKiEl5ZHri5MjRhKKVUCGiXEssw11wZBUWBGZhTE4ZSSoWIawa3Yf+RE8xftysg9WvCUEqpEHFG+yTapcTy/OKtXg3X42uaMJRSKkSICNcMzuC73MNkb/vV9vo1YSilVAi5tFdLEqIdzF5s/y22mjAaMH/Nr/3oo4+SkZHh889VSkG005orY8H3e9jxy3Fb69aEEUJ8vYN/6623ePDBB332eXUhIrzxxhuBDkOpkDBuoDVo6Etf59haryaMulg7D6Z3g3sTrce18wIdEQCFhYVelWvSpAlxcXF+jkYp5WvNE6I5v3tzXrN5rgxNGLW1dh68dwsc2gEY6/G9W/yWNLKysli0aBFPPvkkIoKIkJOTwxdffIGI8MEHH9CvXz+cTicLFixgy5YtXHzxxaSmptKoUSN69+7N+++/X+4z3VssGRkZ/P3vf+eGG24gPj6eli1b8sgjj1Qb28MPP0xqaiqxsbGMGzeuwhDpK1eu5NxzzyUpKYn4+HiGDBnC119/Xa5egMsuuwwROfnam++gVEM1YXAGR/KLeHPVTtvq1AmUSn14B+xZ5335nSuh2K2LfmEevDsFVr3o3WekdofzHvKq6IwZM9i0aROdOnXigQceACA5OZmcnBwAbr/9dh577DHatWtHXFwcu3bt4rzzzuPvf/870dHRzJ07l0svvZS1a9dWOT3r9OnTue+++5g2bRoffvght9xyC0OGDKkwHWupefPmcffdd/Ovf/2Ls846i9dff51//OMfJ+cKBzhy5Ahjx45lxowZiAhPPPEE559/Pps3byYpKYmVK1eSkpLCrFmzuPDCCwkPt2YyPHr0aK2+g1INQa/0xvRKT+SFJVsZO6A1YWFS/ZvqSFsYteWeLKpbX0cJCQk4nU5iYmJITU0lNTX15I4VrGlYzz33XE477TSSk5Pp2bMnkyZNonv37rRr14677rqL3r17V3ud4Nxzz2XKlCm0a9eOm2++mXbt2rFw4cJKy//zn/9k/Pjx3HDDDXTo0IG77rqLfv36lStz9tlnM3bsWDp37kynTp3417/+RVRUFB999BFgJT6AxMREUlNTT76u7XdQqqGYMLgNOT8f5/ON+2ypT1sYpbw80j9pejfX6Sg3Ca3gmvm+iakGMjPLD19/7Ngx7rvvPt5//312795NYWEh+fn59OjRo8rPcd/eokUL9u2r/Me4YcMGrrvuunLrBg4cyI8//njy9b59+/jLX/7C559/zt69eykuLiYvL4/t26seE6e230GphuK33VJJjY/ihSU5DO/czO/12d7CEJEbRWSriOSLyCoRGVpNeRGRW0XkBxE5ISK7RaSGe3c/GH4POKLLr3NEW+sDoFGjRuVe33bbbbz++usnpztds2YN/fr1o6CgoMrPcZ8XXEQoKanbuDXjx49n5cqVTJ8+naVLl7JmzRpatmxZbSy1/Q5KNRSO8DDGDWrN4h8PsHHPEb/XZ2vCEJHLgRnAA0AvYCnwoYikV/G2x4AbgduBzsD5wJd+DrV6PcbAyJlWiwKxHkfOtNb7idPppLi42KuyixcvZty4cYwePZoePXrQsmVLtmzZ4vOYOnfuzLJly8qtc3+9ePFibr75Zi644AK6du1KXFwcu3fvLlfG4XBU+G52fQelQtmVfdOJcoTZMleG3aekpgJzjDGzXK9vFpHfApOBO90Li0hH4GaghzFmQ5lNq/0eqTd6jPFrgnCXkZHBihUryMnJITY2ttyFZXcdOnTg7bff5uKLL8bhcHDfffeRn5/v85j+8Ic/MG7cOPr27cuwYcN44403WL58ebnYOnTowMsvv0z//v05duwYf/rTn3A6nRW+28KFCznzzDOJjIykcePGtn0HpUJZ40ZOLu3dkjdW7WTaiI40jY30W122tTBExAn0AT522/QxMKiSt10M/AT8VkR+EpEcEXlRRFL8GGrQuu2223A6nXTp0oXk5OQqrwE8/vjjpKSkMHToUM477zwGDBjA0KFVnv2rlcsvv5x7772Xu+66i169erFu3TqmTp1arszs2bM5evQoffr04YorrmDChAkVeoI/9thjfP7557Rq1YpevXrZ+h2UCnXXDMqgoKiEV1f4d64MsWvEQxFpAeQCZxpjviyz/h7gamNMRw/veQbIAr4FpgEGeNS1eaAxpsSt/ERgIkB6enqfbdu2eYxlw4YNdO7cua5fSQUp/fdVDdG42Sv4YfdhFt9+Ns6I2rcFRGSVMSbT07ZA3FbrnqHEw7pSYUAkMNYY86Ux5itgLNAP6Fvhg4151hiTaYzJLL01UymlGoIJgzPYd+QEH6zbXX3hWrIzYRwAioFUt/UpwN5K3rMbKDLGbCqzbjNQBFR1oVwppRqUM9onkxLnZNob39LmjvkMfugz3lmd69M6bEsYxpgCYBVwjtumc7DulvJkCRAhIm3LrDsN62K95/NNSinVAP3v2138eryQwmKDAXIP5nHnW+t8mjTsPiX1OJAlIteJSGcRmQG0AJ4BEJEHRaRst+JPgW+A2SLSS0R6AbOB5UC2zbErpVTQemTBRgqLy5/dzyss5pEFG31Wh6231Rpj5opIU+BuoDnwHXC+Maa0tdAcaFumfImIXAjMxOp7kQd8Akx1v+Bdi1gQ8f/YK8pegZi2UqlgsOtgXo3W14btQ4MYY54CnqpkW5aHdbuBy3wZg8PhIC8vj5iYGF9+rAoCeXl5FXqrK9UQtEiMJtdDcmiRGO2hdO00yMEHU1JSyM3N5fjx43pEWk8YYzh+/Di5ubmkpDTIbjqqgZs2oiPRjvBy66Id4UwbUaHHQq01yMEH4+PjAdi1a5fXkw2p4OdwOGjWrNnJf1+lGpJRvdIA61rGroN5tEiMZtqIjifX+0KDTBhgJQ3dsSil6pNRvdJ8miDcNchTUkoppWpOE4ZSSimvaMJQSinlFU0YSimlvKIJQymllFdsG97cbiKyHx1vyteSsAaRVPbSv3tgNNS/e2tjjMfhvuttwlC+JyLZlY2Tr/xH/+6BoX/3ivSUlFJKKa9owlBKKeUVTRiqJp4NdAANlP7dA0P/7m70GoZSSimvaAtDKaWUVzRhKKWU8oomDIWIpIvIeyJyTEQOiMhMEXG6lekuIotEJE9EckXkHikzZaGINBeRV0TkBxEpFpE5tn8RpWqhut+/iESJyBwRWSsihSLyRQDDDagGO7y5sohIODAf+BkYCjQFXgQEuNlVJh5ratwvgb5AR2AOcAx4zPVRkVidnB4CJtr2BZSqA29+/0A4kA88AZwPJNofaXDQi94NnIich/UfprUxZodr3e+B54AUY8xhEZkM/ANoZozJc5W5G5gMtDRuPyIReR844GnKXaWCiTe/f7fyTwDdjDHD7I41GOgpKTUQ2FD6n8VlAVaLoU+ZMl+VJosyZVoAGXYEqZSfePP7Vy6aMFQqsNdt3QGg2LWtsjJ7y2xTKlR58/tXLpowFEBl5yVNFWWkkvVKhRpvfv8KTRgK9lDxSCoJ60Lf3irKpLge3Y/OlAol3vz+lYsmDPU10FlEWpZZdw5wAlhVpsxQEYlyK7MLyLEjSKX8xJvfv3LRhNEAicgUEfnB9fJj4HvgJRHpJSK/AR4BZpW5Q+QV4DgwR0S6icilwB3A42XvkBKR00XkdCAeaOJ63cWu76WUN2rx+0dEurh+20lAbJnfeoOi/TAapiSsvhQYY4pF5ALgKWAJkIeVIG4rLWyMOSQi5wBPAtnAr1j9Lx53+9zVbq9HYk1ileH7r6BUrdXo9+/yAdC6zOvS37rQgGg/DKWUUl7RU1JKKaW8oglDKaWUVzRhKKWU8oomDKWUUl7RhKGUUsormjCUUkp5RROGUkopr2jCUKqWXLOwmTLLARF5X0Q61eAz7hWR7/wZp1K+oglDqbr5FGjuWs4FooG3AxqRUn6iCUOpujlhjNnjWr4BpgOdRCQaQETSROQ1EfnVtcwXkfaubVnAX4GuZVopWa5tU11zSB9zzaH+nIg02KlBVXDQhKGUj4hIHHA5sM4YkyciMcDnWPNBn4k1u9tu4FPXtrlYY3Jt5FQrZa7r40qAW4GuwFVAP+Bf9n0bpSrSwQeVqpvfishR1/NGwA7gfNfrK7AGp7umdFRfEbkB2AdcaIyZ53pvkTFmT9kPNcb8s8zLHBH5E/CuiIw3xpT48fsoVSlNGErVzZfARNfzJsCNwMci0h9rTug2wBGRcoOaxgBtq/pQETkbuBPoDCRgTejjxJrsZ5cP41fKa5owlKqb48aYH0tfiMgq4BBWEgkD1mC1NNz9UtkHikhrYD4wC7gH+BnoDbyKlTSUCghNGEr5lsG6/hADfANcCRwwxhyspHwBVuuhrEysxPBHY0wxgIhc6J9wlfKeXvRWqm4iRSTVtXTGujAdC7wH/BdrXuh3ReRMEWkjImeIyGOld0phTXHbWkR6i0iSiEQCm7H+b97qes+VWBfAlQooTRhK1c1vsO582g0sB/oClxljvjDGHAfOAH4CXgd+AF4EGmPNWgjwJtZsbguB/cCVxpi1wB+AqcB64DoqzgCnlO10xj2llFJe0RaGUkopr2jCUEop5RVNGEoppbyiCUMppZRXNGEopZTyiiYMpZRSXtGEoZRSyiuaMJRSSnlFE4ZSSimv/H91WM1hwrJDXwAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.ticker import StrMethodFormatter\n",
    "\n",
    "def plot_q2():\n",
    "    betas_x = [1/TOTAL_VOCAB, .0001, .001, .004, .01, .1, 1]\n",
    "    test_accuracies_y = [.856, .87, .873, .877, .874, .808, .59]\n",
    "    train_accuracies_y = [.99, .989, .987, .985, .983, .944, .725]\n",
    "    \n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.semilogx(betas_x, test_accuracies_y, betas_x, train_accuracies_y, marker='o')\n",
    "    \n",
    "    ax.legend(['test data', 'train data'])\n",
    "    plt.xlabel('Beta')\n",
    "    plt.ylabel('Accuracy')\n",
    "    \n",
    "    plt.savefig('../res/betas_acc.png', bbox_inches='tight', pad_inches=0.3)\n",
    "\n",
    "plot_q2()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}