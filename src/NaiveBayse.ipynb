{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "import pickle\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load csv into dense matrix, then converts it to sparse matrix\n",
    "#### If \"res/sparse_training.data\" exists, DO NOT run cell as it will take awhile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dense_matrix = np.zeros(shape=(21, 61188), dtype=np.int16)\n",
    "with open('../res/training.csv', 'r') as train_strem:\n",
    "    i=0\n",
    "    for line in train_strem:\n",
    "        line_int = np.array(list(map(int, line.split(','))), dtype=np.int16)\n",
    "        doc_label = line_int[-1]\n",
    "        dense_matrix[doc_label] += line_int[1:-1]\n",
    "        i += 1\n",
    "        print(i)\n",
    "    sparse_training = sparse.csr_matrix(dense_matrix)\n",
    "    sparse.save_npz('../res/sparse_training.data',sparse_training)\n",
    "    print(sparse_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "  (1, 0)\t9\n",
      "  (1, 1)\t53\n",
      "  (1, 2)\t237\n",
      "  (1, 3)\t11\n",
      "  (1, 4)\t48\n",
      "  (1, 5)\t36\n",
      "  (1, 6)\t7\n",
      "  (1, 7)\t1\n",
      "  (1, 8)\t31\n",
      "  (1, 9)\t127\n",
      "  (1, 10)\t5\n",
      "  (1, 11)\t4336\n",
      "  (1, 12)\t19\n",
      "  (1, 13)\t24\n",
      "  (1, 14)\t46\n",
      "  (1, 15)\t597\n",
      "  (1, 16)\t267\n",
      "  (1, 17)\t12\n",
      "  (1, 18)\t9\n",
      "  (1, 19)\t15\n",
      "  (1, 20)\t2\n",
      "  (1, 21)\t3\n",
      "  (1, 22)\t2985\n",
      "  (1, 23)\t4\n",
      "  (1, 24)\t325\n",
      "  :\t:\n",
      "  (20, 61146)\t1\n",
      "  (20, 61147)\t1\n",
      "  (20, 61148)\t1\n",
      "  (20, 61149)\t2\n",
      "  (20, 61150)\t1\n",
      "  (20, 61151)\t1\n",
      "  (20, 61152)\t1\n",
      "  (20, 61153)\t1\n",
      "  (20, 61154)\t1\n",
      "  (20, 61169)\t2\n",
      "  (20, 61170)\t2\n",
      "  (20, 61171)\t2\n",
      "  (20, 61172)\t3\n",
      "  (20, 61173)\t4\n",
      "  (20, 61174)\t2\n",
      "  (20, 61175)\t3\n",
      "  (20, 61176)\t6\n",
      "  (20, 61177)\t1\n",
      "  (20, 61178)\t2\n",
      "  (20, 61179)\t2\n",
      "  (20, 61183)\t2\n",
      "  (20, 61184)\t2\n",
      "  (20, 61185)\t2\n",
      "  (20, 61186)\t2\n",
      "  (20, 61187)\t2\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "sparse_training_data = sparse.load_npz('../res/sparse_training.data.npz')\n",
    "print(sparse_training_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating global vars"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "set_list = [set() for x in range(0, 20)]\n",
    "class_row_dict = dict(zip(list(range(1, 21)), set_list))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Counting Priors and words"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[0.         0.04025    0.052      0.05183333 0.05358333 0.05016667\n",
      " 0.0525     0.0515     0.05116667 0.05408333 0.05233333 0.05383333\n",
      " 0.05325    0.05216667 0.05175    0.05308333 0.05425    0.04833333\n",
      " 0.04941667 0.03891667 0.03558333]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "word_id_ranges = list(range(1, 61189))\n",
    "column_names =  ['doc_id'] + word_id_ranges + ['label']\n",
    "prior_counts = np.zeros(21, dtype=np.int16)\n",
    "i = 0\n",
    "for data_chunk in pd.read_csv('../res/training.csv', header=None, chunksize=200, names=column_names, usecols=['label']): \n",
    "    for _, row in data_chunk.iterrows():\n",
    "        current_label = row['label']\n",
    "        class_row_dict[current_label].add(i)\n",
    "        i += 1\n",
    "\n",
    "for j in range(1, 21):\n",
    "    prior_counts[j] = len(class_row_dict[j])\n",
    "\n",
    "prior_counts = prior_counts / prior_counts.sum()\n",
    "print(prior_counts) "
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Naive Bayes formula from the proj2 PDF"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "uniq_vocab = 61188\n",
    "total_vocab = sparse_training_data.sum()\n",
    "alpha = 1 + 1/total_vocab\n",
    "denom = np.zeros(21, dtype = np.float64)\n",
    "for i in range(1, 21):\n",
    "    denom[i] = sparse_training_data[i].sum() + ((alpha - 1) * total_vocab)\n",
    " \n",
    "do_naive_debug = False \n",
    "def do_naive(row):\n",
    "    max_prob = -math.inf\n",
    "    max_doc_class = -1\n",
    "    non_zero_indices = row.nonzero()[0]\n",
    "    for doc_label in range(1, 21):\n",
    "        running_sum = 0\n",
    "        for word in non_zero_indices:\n",
    "            running_sum += math.log2((sparse_training_data[doc_label,word] + alpha - 1)/denom[doc_label])\n",
    "        new_prob = running_sum + math.log2(prior_counts[doc_label])\n",
    "        if new_prob > max_prob:\n",
    "            max_prob = new_prob\n",
    "            max_doc_class = doc_label\n",
    "    assert(max_doc_class != -1)\n",
    "    if do_naive_debug:\n",
    "        print(f\"{max_doc_class}: {max_prob}\")\n",
    "    return max_doc_class"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Testing\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# With training data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "i=0; pred: 14; true: 14\n",
      "i=100; pred: 16; true: 16\n",
      "i=200; pred: 9; true: 9\n",
      "i=300; pred: 1; true: 1\n",
      "i=400; pred: 1; true: 1\n",
      "i=500; pred: 6; true: 6\n",
      "i=600; pred: 10; true: 10\n",
      "i=700; pred: 6; true: 6\n",
      "i=800; pred: 10; true: 10\n",
      "i=900; pred: 3; true: 3\n",
      "i=1000; pred: 4; true: 4\n",
      "i=1100; pred: 11; true: 11\n",
      "i=1200; pred: 16; true: 16\n",
      "i=1300; pred: 6; true: 6\n",
      "i=1400; pred: 9; true: 9\n",
      "i=1500; pred: 8; true: 8\n",
      "i=1600; pred: 7; true: 7\n",
      "i=1700; pred: 1; true: 1\n",
      "i=1800; pred: 10; true: 10\n",
      "i=1900; pred: 5; true: 5\n",
      "i=2000; pred: 15; true: 15\n",
      "i=2100; pred: 11; true: 11\n",
      "i=2200; pred: 9; true: 9\n",
      "i=2300; pred: 12; true: 12\n",
      "i=2400; pred: 11; true: 11\n",
      "i=2500; pred: 20; true: 20\n",
      "i=2600; pred: 1; true: 1\n",
      "i=2700; pred: 2; true: 2\n",
      "i=2800; pred: 16; true: 16\n",
      "i=2900; pred: 5; true: 5\n",
      "i=3000; pred: 2; true: 2\n",
      "i=3100; pred: 1; true: 1\n",
      "i=3200; pred: 2; true: 2\n",
      "i=3300; pred: 16; true: 16\n",
      "i=3400; pred: 19; true: 19\n",
      "i=3500; pred: 4; true: 4\n",
      "i=3600; pred: 4; true: 4\n",
      "i=3700; pred: 1; true: 1\n",
      "i=3800; pred: 13; true: 13\n",
      "i=3900; pred: 16; true: 16\n",
      "i=4000; pred: 1; true: 1\n",
      "i=4100; pred: 3; true: 3\n",
      "i=4200; pred: 6; true: 6\n",
      "i=4300; pred: 10; true: 10\n",
      "i=4400; pred: 19; true: 19\n",
      "i=4500; pred: 11; true: 11\n",
      "i=4600; pred: 13; true: 13\n",
      "i=4700; pred: 3; true: 3\n",
      "i=4800; pred: 10; true: 10\n",
      "i=4900; pred: 14; true: 14\n",
      "i=5000; pred: 20; true: 20\n",
      "i=5100; pred: 11; true: 11\n",
      "i=5200; pred: 7; true: 7\n",
      "i=5300; pred: 4; true: 4\n",
      "i=5400; pred: 20; true: 20\n",
      "i=5500; pred: 15; true: 15\n",
      "i=5600; pred: 4; true: 4\n",
      "i=5700; pred: 7; true: 7\n",
      "i=5800; pred: 3; true: 3\n",
      "i=5900; pred: 10; true: 10\n",
      "i=6000; pred: 16; true: 16\n",
      "i=6100; pred: 9; true: 9\n",
      "i=6200; pred: 17; true: 17\n",
      "i=6300; pred: 6; true: 6\n",
      "i=6400; pred: 1; true: 1\n",
      "i=6500; pred: 18; true: 18\n",
      "i=6600; pred: 15; true: 15\n",
      "i=6700; pred: 17; true: 17\n",
      "i=6800; pred: 20; true: 20\n",
      "i=6900; pred: 19; true: 19\n",
      "i=7000; pred: 1; true: 1\n",
      "i=7100; pred: 9; true: 9\n",
      "i=7200; pred: 5; true: 5\n",
      "i=7300; pred: 8; true: 8\n",
      "i=7400; pred: 14; true: 14\n",
      "i=7500; pred: 8; true: 8\n",
      "i=7600; pred: 17; true: 17\n",
      "i=7700; pred: 6; true: 6\n",
      "i=7800; pred: 8; true: 8\n",
      "i=7900; pred: 2; true: 2\n",
      "i=8000; pred: 9; true: 9\n",
      "i=8100; pred: 14; true: 14\n",
      "i=8200; pred: 1; true: 1\n",
      "i=8300; pred: 11; true: 11\n",
      "i=8400; pred: 11; true: 11\n",
      "i=8500; pred: 5; true: 5\n",
      "i=8600; pred: 18; true: 18\n",
      "i=8700; pred: 5; true: 5\n",
      "i=8800; pred: 18; true: 18\n",
      "i=8900; pred: 17; true: 17\n",
      "i=9000; pred: 13; true: 14\n",
      "i=9100; pred: 17; true: 17\n",
      "i=9200; pred: 4; true: 4\n",
      "i=9300; pred: 19; true: 19\n",
      "i=9400; pred: 6; true: 6\n",
      "i=9500; pred: 17; true: 17\n",
      "i=9600; pred: 2; true: 2\n",
      "i=9700; pred: 18; true: 18\n",
      "i=9800; pred: 14; true: 14\n",
      "i=9900; pred: 6; true: 6\n",
      "i=10000; pred: 5; true: 5\n",
      "i=10100; pred: 4; true: 4\n",
      "i=10200; pred: 7; true: 7\n",
      "i=10300; pred: 1; true: 1\n",
      "i=10400; pred: 16; true: 16\n",
      "i=10500; pred: 2; true: 2\n",
      "i=10600; pred: 16; true: 16\n",
      "i=10700; pred: 6; true: 6\n",
      "i=10800; pred: 19; true: 19\n",
      "i=10900; pred: 3; true: 3\n",
      "i=11000; pred: 20; true: 20\n",
      "i=11100; pred: 11; true: 11\n",
      "i=11200; pred: 8; true: 8\n",
      "i=11300; pred: 6; true: 6\n",
      "i=11400; pred: 13; true: 13\n",
      "i=11500; pred: 6; true: 6\n",
      "i=11600; pred: 17; true: 17\n",
      "i=11700; pred: 4; true: 4\n",
      "i=11800; pred: 1; true: 1\n",
      "i=11900; pred: 1; true: 1\n",
      "accuracy: 0.9902491874322861\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "with open('../res/training.csv', 'r') as test_stream:\n",
    "    correct = 0\n",
    "    \n",
    "    for line in test_stream:\n",
    "        test_array = np.array(list(map(int,line.split(','))))\n",
    "        doc_id = test_array[0]\n",
    "        doc_label = test_array[-1]\n",
    "        predicted_label = do_naive(test_array[1:-1])\n",
    "        if i % 125 == 0:\n",
    "            print(f\"i={i}; pred: {predicted_label}; true: {doc_label}\")\n",
    "        if predicted_label == doc_label:\n",
    "            correct += 1\n",
    "    print(f\"accuracy: {(correct / 12000) * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# With testing data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "with open('../res/testing.csv', 'r') as test_stream, open('../results/out.csv', 'w') as out_stream:\n",
    "    out_stream.write(\"id,class\\n\")\n",
    "    for line in test_stream:\n",
    "        test_array = np.array(list(map(int, line.split(','))))\n",
    "        doc_id = test_array[0]\n",
    "        predicted_label = do_naive(test_array[1:])    \n",
    "        out_stream.write(f\"{doc_id},{predicted_label}\\n\")\n",
    "print(\"File written\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}